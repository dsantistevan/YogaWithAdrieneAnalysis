{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d371834d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python39\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5755a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.9.6\n",
      "IPython version      : 7.26.0\n",
      "\n",
      "numpy       : 1.19.5\n",
      "pandas      : 1.3.2\n",
      "torch       : 1.11.0+cpu\n",
      "transformers: 4.20.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -v -p numpy,pandas,torch,transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48c63ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c38d57a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>Prequalified sentiment</th>\n",
       "      <th>Information</th>\n",
       "      <th>Opinion</th>\n",
       "      <th>Advice</th>\n",
       "      <th>Impression</th>\n",
       "      <th>Progress</th>\n",
       "      <th>Exercise</th>\n",
       "      <th>Body</th>\n",
       "      <th>Video</th>\n",
       "      <th>Length</th>\n",
       "      <th>Reviewer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello and can I ask you if I can do also other...</td>\n",
       "      <td>-0.894868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a person with Lyme Disease who is chronical...</td>\n",
       "      <td>-0.992691</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>273</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Has anyone lost weight from this? ‚ù§Ô∏è</td>\n",
       "      <td>-0.997208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doing this to start my fourth year of university</td>\n",
       "      <td>0.991657</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Simply love it thought I was in shape until this</td>\n",
       "      <td>0.999816</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>Mil gracias yoga with ADRIANE!!!</td>\n",
       "      <td>0.730353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>32</td>\n",
       "      <td>D*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>So grateful for you and for this daily practic...</td>\n",
       "      <td>0.99983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>69</td>\n",
       "      <td>D*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>Thank you ‚ò∫Ô∏è\\n\\nMy partner and I do it every e...</td>\n",
       "      <td>0.99747</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>245</td>\n",
       "      <td>D*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>Thank you!</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>D*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>Thank you and Namaskaram üôè</td>\n",
       "      <td>0.999655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>27</td>\n",
       "      <td>D*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1613 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  \\\n",
       "1000                                                      \n",
       "0     Hello and can I ask you if I can do also other...   \n",
       "1     As a person with Lyme Disease who is chronical...   \n",
       "3                  Has anyone lost weight from this? ‚ù§Ô∏è   \n",
       "4      doing this to start my fourth year of university   \n",
       "5      Simply love it thought I was in shape until this   \n",
       "...                                                 ...   \n",
       "2515                   Mil gracias yoga with ADRIANE!!!   \n",
       "2516  So grateful for you and for this daily practic...   \n",
       "2517  Thank you ‚ò∫Ô∏è\\n\\nMy partner and I do it every e...   \n",
       "2518                                         Thank you!   \n",
       "2519                         Thank you and Namaskaram üôè   \n",
       "\n",
       "     Prequalified sentiment Information Opinion Advice Impression Progress  \\\n",
       "1000                                                                         \n",
       "0                 -0.894868         0.0     0.0    0.7        0.0      0.0   \n",
       "1                 -0.992691         0.5     0.3    0.9        0.0      0.0   \n",
       "3                 -0.997208         0.0     0.0    0.5        0.6      0.0   \n",
       "4                  0.991657         0.5     0.0    0.0        0.0      0.8   \n",
       "5                  0.999816         0.2     0.8    0.0        0.4      0.2   \n",
       "...                     ...         ...     ...    ...        ...      ...   \n",
       "2515               0.730353         0.0     0.8    0.0        0.8      0.0   \n",
       "2516                0.99983         0.0     0.8    0.0        0.8      0.0   \n",
       "2517                0.99747         0.6     0.0    0.0        0.7      0.8   \n",
       "2518               0.999858         0.2     0.7    0.0        0.7      0.0   \n",
       "2519               0.999655         0.0     0.8    0.0        0.8      0.0   \n",
       "\n",
       "     Exercise Body Video Length Reviewer  \n",
       "1000                                      \n",
       "0         0.4  0.0   0.0     74        J  \n",
       "1         0.4  0.0   0.6    273        J  \n",
       "3         0.0  0.8   0.0     36        J  \n",
       "4         0.0  0.0   0.0     48        J  \n",
       "5         0.0  0.5   0.0     48        J  \n",
       "...       ...  ...   ...    ...      ...  \n",
       "2515      0.0  0.7   0.6     32       D*  \n",
       "2516      0.0  0.7   0.6     69       D*  \n",
       "2517      0.0  0.7   0.5    245       D*  \n",
       "2518      0.0  0.2   0.5     10       D*  \n",
       "2519      0.0  0.7   0.6     27       D*  \n",
       "\n",
       "[1613 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = pd.read_csv(\"comments_training_dataset - Sheet1.csv\", index_col=\"1000\")\n",
    "df = df_2.dropna()\n",
    "df = df.T\n",
    "df.pop(450)\n",
    "df = df.T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20e3012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1613 entries, 0 to 2519\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   comment                 1613 non-null   object\n",
      " 1   Prequalified sentiment  1613 non-null   object\n",
      " 2   Information             1613 non-null   object\n",
      " 3   Opinion                 1613 non-null   object\n",
      " 4   Advice                  1613 non-null   object\n",
      " 5   Impression              1613 non-null   object\n",
      " 6   Progress                1613 non-null   object\n",
      " 7   Exercise                1613 non-null   object\n",
      " 8   Body                    1613 non-null   object\n",
      " 9   Video                   1613 non-null   object\n",
      " 10  Length                  1613 non-null   object\n",
      " 11  Reviewer                1613 non-null   object\n",
      "dtypes: object(12)\n",
      "memory usage: 163.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cadcd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = \"dsantistevan/bert-base-cased-bert-yoga-finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed7759d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e254b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lens = []\n",
    "\n",
    "for txt in df.comment:\n",
    "    tokens = tokenizer.encode(txt)\n",
    "    token_lens.append(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb418e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 488,
       "width": 744
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(token_lens)\n",
    "plt.xlim([0, 560]);\n",
    "plt.xlabel('Token count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ab3d0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b632094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YTCommentDataset(Dataset):\n",
    "\n",
    "    def __init__(self, comments, targets, tokenizer, max_len):\n",
    "        self.comments = comments\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comments)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        comment = str(self.comments[item])\n",
    "        target = self.targets[item:item+1]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "          comment,\n",
    "          add_special_tokens=True,\n",
    "          max_length=self.max_len,\n",
    "          return_token_type_ids=False,\n",
    "          pad_to_max_length=True,\n",
    "          return_attention_mask=True,\n",
    "          return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "          'comment_text': comment,\n",
    "          'input_ids': encoding['input_ids'].flatten(),\n",
    "          'attention_mask': encoding['attention_mask'].flatten(),\n",
    "          'targets': torch.FloatTensor(list(target))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2a40f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c95262a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1290, 12), (161, 12), (162, 12))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56a2db4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    ds = YTCommentDataset(\n",
    "        comments=df.comment.to_numpy(),\n",
    "        targets=df.Opinion.to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "    )\n",
    "\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8cb54a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e77d61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['comment_text', 'input_ids', 'attention_mask', 'targets'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = next(iter(train_data_loader))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b212148c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7000],\n",
      "        [0.0000],\n",
      "        [0.8000],\n",
      "        [0.5000],\n",
      "        [0.8000],\n",
      "        [0.7000],\n",
      "        [0.0000],\n",
      "        [0.3000],\n",
      "        [0.8000],\n",
      "        [0.6000],\n",
      "        [0.0000],\n",
      "        [0.6000],\n",
      "        [0.6000],\n",
      "        [0.5000],\n",
      "        [0.2000],\n",
      "        [0.7000]])\n"
     ]
    }
   ],
   "source": [
    "print(data['targets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cc8345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentScorer(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SentimentScorer, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        pooled_output = self.bert(\n",
    "          input_ids=input_ids,\n",
    "          attention_mask=attention_mask\n",
    "        )[1]\n",
    "        output = self.drop(pooled_output)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59f2c45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dsantistevan/bert-base-cased-bert-yoga-finetuned were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at dsantistevan/bert-base-cased-bert-yoga-finetuned and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = SentimentScorer()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b02e8ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_params = set()\n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False\n",
    "    bert_params.add(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d5674be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-8.9955e-03,  1.0302e-02,  1.1558e-02,  2.2886e-02, -1.4123e-02,\n",
      "          2.6413e-02,  2.1788e-02,  3.4780e-02,  8.4839e-03, -2.4000e-02,\n",
      "          2.9890e-02, -3.2827e-02,  4.5486e-03,  8.7773e-03,  4.8264e-03,\n",
      "          2.2931e-03, -1.0624e-02, -2.4483e-02,  1.0868e-02, -3.1929e-03,\n",
      "          8.1765e-03,  3.1240e-02, -9.6459e-03,  3.4003e-02, -2.7085e-02,\n",
      "         -1.8845e-02,  8.7198e-03, -1.6218e-02, -1.6375e-02,  2.2257e-02,\n",
      "         -1.9899e-02,  2.9875e-02,  2.9006e-02, -2.7636e-02, -3.0620e-02,\n",
      "          6.2384e-03,  2.4154e-02, -2.9063e-02,  2.7422e-02, -2.5325e-03,\n",
      "         -2.3274e-02, -1.2020e-02,  2.7578e-03, -1.5582e-03,  9.0998e-04,\n",
      "         -6.1661e-03, -3.5039e-02,  6.0533e-03,  1.2634e-02,  2.9165e-03,\n",
      "         -1.1201e-02,  1.5335e-02,  4.2582e-03,  4.3833e-03, -2.3553e-02,\n",
      "          2.5123e-03, -4.2241e-03, -7.3261e-03, -3.6536e-04,  2.8893e-02,\n",
      "          7.4584e-05,  1.1374e-02,  1.3125e-02, -5.1762e-03,  2.2858e-02,\n",
      "         -2.6297e-02, -2.2618e-02,  2.2057e-02, -2.2034e-02,  2.1601e-02,\n",
      "         -7.8686e-03, -1.2036e-02,  3.5091e-02, -2.8285e-02,  1.1722e-02,\n",
      "         -3.4467e-02,  3.4920e-02,  8.3441e-03,  2.3192e-02, -9.7512e-03,\n",
      "         -5.7680e-03, -1.0481e-02,  3.5452e-02,  1.8780e-02, -1.0749e-02,\n",
      "          1.9005e-02, -1.9687e-02, -2.2935e-02, -2.9687e-02,  9.5594e-04,\n",
      "         -2.4709e-03,  3.1553e-02, -1.0081e-02, -1.8035e-02,  9.4054e-03,\n",
      "         -2.5116e-02,  2.7816e-02, -3.2930e-02, -3.1512e-02, -3.4933e-02,\n",
      "         -6.5375e-03,  2.2457e-02,  1.7210e-02,  3.5707e-02,  1.4374e-03,\n",
      "         -1.1636e-02, -8.2515e-03, -2.8153e-02,  3.0120e-02,  1.4782e-02,\n",
      "          3.5296e-02, -3.1277e-02,  4.7420e-03,  6.3068e-03, -7.6735e-03,\n",
      "          1.5364e-02,  7.8437e-03,  1.2024e-02,  1.6170e-02,  9.2078e-03,\n",
      "         -8.2700e-03, -1.4292e-02, -2.8120e-02,  2.7207e-02,  1.3706e-02,\n",
      "          3.3935e-02, -2.5941e-02, -1.0341e-02,  9.2619e-04, -1.9018e-03,\n",
      "         -2.7939e-03, -2.3720e-03, -1.9977e-02, -1.0788e-03, -1.8298e-02,\n",
      "          9.0405e-03,  1.3716e-02, -1.8591e-02,  2.9169e-02, -9.8113e-03,\n",
      "          2.6863e-02,  1.7103e-02,  5.6755e-03,  2.9995e-02, -2.9181e-02,\n",
      "         -1.3990e-02,  6.8490e-03,  2.3293e-02,  2.8441e-02, -2.6234e-02,\n",
      "         -1.8106e-03, -2.0500e-02, -3.2764e-02, -9.9187e-03, -5.7153e-04,\n",
      "         -3.3030e-02,  9.0434e-03,  1.0652e-03, -1.9148e-02, -2.3884e-02,\n",
      "         -3.1367e-02, -3.4973e-02, -3.5450e-03,  3.4573e-02,  1.7881e-02,\n",
      "         -1.1734e-02,  1.6826e-02, -3.4434e-02, -1.9491e-02, -3.5913e-02,\n",
      "          2.4633e-02,  7.8300e-03,  3.1904e-02, -2.1709e-02, -9.6746e-03,\n",
      "          1.7521e-02, -2.6373e-02, -1.1891e-02, -2.2508e-02,  3.1639e-02,\n",
      "          3.0249e-03,  1.6377e-02, -4.0455e-03, -2.7825e-02, -3.0957e-02,\n",
      "          3.5057e-03, -5.1712e-03,  7.4933e-03, -1.6532e-02,  3.4385e-02,\n",
      "         -1.6039e-02, -7.7472e-03, -6.5175e-03,  1.2708e-02,  1.8589e-03,\n",
      "          1.0641e-02, -1.5365e-02, -2.7554e-02,  4.9319e-03,  1.6406e-03,\n",
      "         -2.3896e-02,  1.5869e-02, -5.4733e-03, -8.9535e-03,  1.6263e-02,\n",
      "          2.4148e-02,  3.3416e-02,  3.4814e-02,  7.0800e-03,  3.1519e-03,\n",
      "         -6.1430e-06,  1.0615e-02, -2.2346e-02,  2.5921e-02, -2.0634e-02,\n",
      "          3.2727e-02, -2.7550e-02,  2.4113e-02, -1.3679e-02,  1.0048e-02,\n",
      "         -2.9278e-02, -1.1452e-02,  1.0968e-02,  4.6423e-03,  2.3337e-03,\n",
      "          3.0148e-02, -2.2917e-02,  2.1215e-02, -1.0815e-02,  2.4219e-02,\n",
      "         -1.7524e-02,  2.5330e-02, -1.6102e-02,  2.4900e-02,  3.0042e-02,\n",
      "         -2.4931e-02,  3.1332e-02, -1.0883e-02,  2.0969e-02, -2.1754e-02,\n",
      "          1.4989e-02,  1.9042e-02, -1.1524e-02,  1.2462e-02, -4.3873e-03,\n",
      "          7.0387e-03, -3.3166e-02,  1.9430e-02,  2.4376e-02,  3.3931e-02,\n",
      "          6.9447e-03, -1.1246e-03, -1.5094e-02, -4.7602e-03, -2.4643e-02,\n",
      "         -3.5174e-02, -2.6071e-02,  3.2893e-02,  1.3841e-02,  4.4214e-03,\n",
      "          1.9852e-02,  1.2778e-02,  2.5650e-02, -2.1606e-02, -3.0101e-02,\n",
      "         -2.3557e-02, -1.0974e-02,  2.4003e-02,  2.6609e-02, -6.7405e-03,\n",
      "          7.3944e-04,  6.2097e-03, -1.4903e-03,  3.2163e-02,  8.5586e-03,\n",
      "          3.1667e-02,  2.9043e-02, -4.5025e-03,  1.4587e-02,  2.7876e-02,\n",
      "          5.1382e-03, -7.2754e-03, -8.6779e-03,  1.2516e-02,  2.9863e-02,\n",
      "          2.8956e-02,  1.2669e-02, -9.7545e-03,  8.4436e-03,  5.2330e-03,\n",
      "          1.1903e-02, -8.4919e-03, -5.0080e-03, -3.2440e-02, -8.4829e-03,\n",
      "         -9.2604e-03,  1.7904e-02,  1.7275e-02, -5.0902e-03,  3.7378e-03,\n",
      "          1.1828e-02, -8.7689e-03,  3.1919e-02,  1.7949e-02, -4.2966e-03,\n",
      "         -1.5317e-02, -3.4624e-02, -2.6983e-02,  1.6826e-02,  2.2051e-02,\n",
      "          2.0505e-02,  5.4713e-03, -2.1954e-02, -1.1306e-02,  8.4366e-03,\n",
      "         -3.4433e-02,  1.1079e-02,  2.0958e-02,  4.9667e-03,  2.5913e-02,\n",
      "         -2.7058e-02, -3.2335e-02, -1.1670e-02,  1.7610e-02, -3.2879e-02,\n",
      "          1.3018e-02, -3.2697e-02, -1.9513e-02,  1.5344e-02,  1.6771e-02,\n",
      "         -2.8281e-03,  9.1103e-03, -2.1981e-02, -1.3938e-02, -1.8296e-02,\n",
      "          3.2303e-02, -7.2569e-03, -2.8642e-03, -1.3503e-02,  7.4565e-03,\n",
      "         -2.5617e-02, -2.1040e-02,  7.4676e-03,  3.0604e-02, -2.8506e-02,\n",
      "         -3.1661e-02,  5.5292e-03, -3.2427e-02,  2.8941e-02, -2.8244e-03,\n",
      "         -5.6913e-03, -2.8129e-02,  2.3993e-03, -8.8393e-04, -7.2428e-03,\n",
      "          1.1806e-02, -7.9346e-04,  2.4056e-02,  2.4811e-03, -3.2575e-02,\n",
      "         -3.2096e-03, -1.1775e-02,  2.7866e-02,  3.2539e-02, -6.9540e-03,\n",
      "         -9.3583e-03,  2.2365e-02, -1.8594e-02,  3.4262e-02, -1.5090e-02,\n",
      "         -9.9749e-03,  1.6205e-02,  2.6608e-02,  1.3799e-02, -2.0528e-02,\n",
      "          1.8204e-02, -2.3408e-02,  4.3391e-03, -2.8120e-02, -1.8534e-02,\n",
      "          4.9770e-04,  1.7461e-02,  2.8362e-02,  3.3155e-02, -2.5681e-02,\n",
      "         -2.6164e-02,  3.1340e-02,  6.4645e-03,  3.4037e-02,  2.8092e-02,\n",
      "          1.4318e-03, -8.5683e-03, -3.2030e-02, -1.8609e-02,  1.1267e-02,\n",
      "         -2.4825e-02, -4.3608e-03, -2.4007e-02, -1.2689e-02,  4.8546e-03,\n",
      "          2.5038e-02,  2.2955e-02, -1.0552e-02, -1.8362e-02,  2.7084e-02,\n",
      "         -3.4954e-05,  5.9481e-03, -3.0833e-02,  2.9230e-02,  3.0042e-03,\n",
      "         -4.4913e-03,  2.0950e-02, -2.6469e-02, -1.3617e-02, -2.8664e-02,\n",
      "         -3.5659e-02,  3.5525e-02,  1.7962e-03,  5.7428e-03, -5.3632e-03,\n",
      "         -8.6015e-03, -9.3248e-03, -2.7619e-02,  6.4371e-03, -1.5560e-02,\n",
      "         -5.6244e-05, -1.7310e-02, -2.8731e-02, -1.3050e-02,  1.2141e-03,\n",
      "          3.3573e-02,  8.5283e-03, -1.1425e-02,  7.1063e-04,  6.4393e-03,\n",
      "          3.5425e-02, -7.0529e-03,  2.7211e-02, -3.2543e-02, -4.9381e-03,\n",
      "         -1.4616e-02,  2.4599e-03, -2.5939e-02, -2.6174e-02,  2.8174e-02,\n",
      "          2.4344e-02,  2.4725e-02, -1.2135e-02,  2.9809e-02, -2.7485e-02,\n",
      "         -1.9464e-02, -3.4887e-02,  1.6240e-03, -6.3749e-03,  2.6568e-02,\n",
      "         -3.1992e-02,  1.8599e-03, -9.6446e-04, -2.8081e-02,  2.2742e-02,\n",
      "          2.5700e-02, -1.0245e-02,  1.9858e-02, -4.8116e-05, -9.8798e-03,\n",
      "          1.3912e-02, -1.2373e-02, -3.0450e-03, -2.8262e-02, -1.2732e-02,\n",
      "         -3.3743e-02,  1.4864e-02,  3.5783e-02, -3.4314e-03, -6.3175e-03,\n",
      "         -7.1592e-03, -3.4035e-02,  7.5059e-04,  2.8724e-02, -2.2684e-02,\n",
      "         -9.2204e-03, -3.5219e-02, -2.1566e-02, -2.4139e-02,  2.1595e-02,\n",
      "          2.2631e-02,  3.4623e-02, -1.8561e-02, -6.5621e-03,  1.5449e-02,\n",
      "         -2.7611e-02,  6.1593e-03, -2.7570e-02, -4.6544e-03, -1.8131e-02,\n",
      "          6.3228e-03,  1.4276e-02, -2.6916e-02,  2.7683e-02, -1.2658e-02,\n",
      "         -3.4515e-02, -2.8894e-03, -2.8900e-02, -2.7818e-03,  1.9822e-02,\n",
      "          3.2694e-02,  2.7925e-03,  3.4995e-02,  3.6049e-02,  1.9227e-02,\n",
      "          9.2804e-04, -6.7969e-03, -6.5017e-03,  2.4001e-02,  9.4623e-03,\n",
      "         -3.1883e-02, -9.5991e-03,  2.1917e-02, -6.9349e-03, -5.9933e-03,\n",
      "          1.4502e-02, -1.0900e-02, -1.3369e-02, -1.6262e-02, -1.8006e-02,\n",
      "         -1.4188e-02,  3.3005e-04,  2.4630e-02, -1.0106e-02,  3.1617e-02,\n",
      "          3.4208e-02, -7.6037e-03, -1.3851e-02, -9.1603e-03,  9.0047e-04,\n",
      "         -8.3208e-03, -3.0215e-03, -2.4633e-04,  9.9033e-03,  2.0894e-02,\n",
      "         -1.4415e-02,  1.7524e-02,  2.5506e-03, -1.2316e-02, -2.6799e-02,\n",
      "         -1.6535e-02, -1.8008e-02,  1.6091e-02,  1.6114e-02,  8.5362e-03,\n",
      "          2.3097e-02, -1.5520e-02,  6.3277e-03, -5.2171e-03,  1.9682e-03,\n",
      "          8.7834e-03,  2.9717e-02,  8.6949e-03,  2.2798e-02, -3.1880e-03,\n",
      "          1.6453e-02,  2.3828e-02, -2.3672e-03,  1.1730e-02, -1.1086e-02,\n",
      "          1.3575e-02,  8.9874e-03,  1.0242e-02,  3.2169e-02, -2.4953e-02,\n",
      "         -5.0529e-03,  3.5033e-02,  5.6678e-03,  4.6907e-03, -1.3533e-02,\n",
      "         -2.9166e-02, -2.4662e-02, -2.1510e-02, -7.7540e-03,  1.2467e-02,\n",
      "         -2.6759e-02,  2.5810e-02, -1.7625e-02,  2.9640e-02, -1.1093e-02,\n",
      "          1.7510e-03,  1.7817e-02, -3.0384e-02,  9.1731e-03, -3.3196e-02,\n",
      "          1.5743e-02,  1.4583e-02,  1.4253e-02,  1.4575e-03,  1.0260e-02,\n",
      "         -7.5614e-03,  3.1516e-02,  6.1362e-03,  1.0473e-02,  1.0918e-02,\n",
      "          1.8831e-02,  3.5711e-02, -2.0103e-03, -3.1630e-02,  1.0918e-02,\n",
      "          3.3075e-02, -1.5092e-02,  2.7992e-02,  5.8394e-03,  5.7958e-03,\n",
      "         -2.7602e-02, -1.5877e-02,  3.2616e-02, -2.8714e-03, -7.2519e-03,\n",
      "         -2.3142e-02,  1.7271e-02,  2.9215e-02,  1.6129e-02,  1.5649e-02,\n",
      "         -1.1845e-02,  2.4278e-02, -3.4093e-02, -1.8999e-02,  3.0763e-02,\n",
      "         -2.3452e-02, -3.5167e-02, -2.1633e-02, -1.8260e-02,  1.9815e-02,\n",
      "          2.6049e-02, -2.1778e-02,  2.2000e-02, -3.3244e-02,  3.4394e-02,\n",
      "          2.3499e-02,  3.2273e-02,  2.3239e-02,  2.7991e-02, -3.0531e-02,\n",
      "          2.9666e-03, -3.8355e-03, -2.7716e-02,  8.1628e-04,  2.3982e-02,\n",
      "         -5.4179e-03, -4.2227e-03, -1.7539e-02, -2.9928e-02, -1.8320e-02,\n",
      "          1.9959e-02,  1.0421e-02, -1.2672e-02, -2.2542e-02,  2.2989e-02,\n",
      "          2.1769e-03,  6.3852e-03, -1.6078e-02, -2.0620e-02, -1.6675e-02,\n",
      "         -1.7785e-02,  1.1107e-02, -2.1122e-03, -4.3431e-03,  3.3759e-02,\n",
      "          7.7857e-03,  1.2312e-02,  2.6056e-02, -2.0168e-02, -2.1507e-02,\n",
      "         -2.9891e-02,  2.0487e-02, -3.4379e-02, -2.3227e-02, -1.1670e-02,\n",
      "          2.4918e-02, -3.4297e-02, -3.1333e-02,  1.7002e-03, -1.1749e-02,\n",
      "          5.8740e-04, -2.9237e-02, -3.3752e-02,  6.0441e-03,  1.0462e-02,\n",
      "         -2.7409e-02,  3.5237e-02,  1.4845e-02, -1.4648e-02, -1.9906e-02,\n",
      "          1.2883e-03, -3.1168e-02, -4.6564e-03,  8.5367e-03, -7.2804e-03,\n",
      "         -3.0806e-02, -3.2580e-02,  2.2220e-02, -8.9341e-03, -3.4260e-02,\n",
      "         -2.6386e-02,  1.3821e-02,  4.3740e-03,  1.2363e-02,  1.7585e-02,\n",
      "         -1.7700e-02,  1.8512e-02, -3.3244e-02, -2.3973e-03, -1.9632e-02,\n",
      "          2.8428e-02, -2.3737e-02, -2.5774e-02,  3.3721e-02, -3.3976e-02,\n",
      "          3.1401e-02,  1.3131e-02, -3.5843e-02, -3.3604e-02, -2.7960e-02,\n",
      "          3.4083e-02,  3.2417e-02, -5.4042e-03,  3.5189e-02,  2.7819e-02,\n",
      "          2.5673e-02,  7.0613e-03, -2.4302e-02, -2.7512e-02,  4.8765e-03,\n",
      "         -2.8508e-02, -2.4634e-03, -6.4162e-03,  1.1544e-02, -2.9092e-02,\n",
      "         -3.6544e-03, -1.4991e-02,  1.6309e-03,  2.9591e-03,  7.5358e-03,\n",
      "          7.3873e-03, -1.9728e-02, -2.9724e-02,  2.3216e-02, -1.8369e-03,\n",
      "         -9.0412e-03,  3.2204e-02,  1.6616e-03,  7.7518e-03,  2.2092e-04,\n",
      "         -1.0847e-02,  2.2864e-03, -7.2790e-03, -3.5467e-02, -3.1478e-03,\n",
      "         -2.8254e-02, -9.9357e-03, -1.1975e-02,  1.7718e-02,  1.6207e-02,\n",
      "         -2.5255e-02,  2.8218e-02,  1.8365e-02,  4.8029e-04,  2.9301e-02,\n",
      "         -1.7956e-02, -3.5007e-02,  3.1466e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0323], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for param in model.parameters():\n",
    "    if param not in bert_params:\n",
    "        print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "918a7304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for i in model.out.parameters():\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "639cc0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "optimizer = torch.optim.SGD(model.out.parameters(), lr=0.002)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.MSELoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2e61f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "  model, \n",
    "  data_loader, \n",
    "  loss_fn, \n",
    "  optimizer, \n",
    "  device, \n",
    "  scheduler, \n",
    "  n_examples\n",
    "):\n",
    "    model = model.train()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for d in data_loader:\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "          input_ids=input_ids,\n",
    "          attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a8b61b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "            )\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de5d1bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n",
      "Train loss 0.15677634028740872 accuracy 3.66046511627907\n",
      "Val   loss 0.09565027024258267 accuracy 3.8819875776397517\n",
      "\n",
      "Epoch 2/20\n",
      "----------\n",
      "Train loss 0.1272106800734261 accuracy 3.66046511627907\n",
      "Val   loss 0.09371052276004445 accuracy 3.8819875776397517\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "Train loss 0.12436604481420399 accuracy 3.66046511627907\n",
      "Val   loss 0.09270040589300069 accuracy 3.8819875776397517\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "Train loss 0.11957440695460932 accuracy 3.66046511627907\n",
      "Val   loss 0.09197684716094624 accuracy 3.8819875776397517\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "Train loss 0.11848034907454326 accuracy 3.66046511627907\n",
      "Val   loss 0.09107653898271648 accuracy 3.8819875776397517\n",
      "\n",
      "Epoch 6/20\n",
      "----------\n",
      "Train loss 0.11568454919773856 accuracy 3.66046511627907\n",
      "Val   loss 0.09037306125868451 accuracy 3.8819875776397517\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "Train loss 0.11705955012161055 accuracy 3.66046511627907\n",
      "Val   loss 0.08974489738995378 accuracy 3.8819875776397517\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "Train loss 0.11382663884648571 accuracy 3.66046511627907\n",
      "Val   loss 0.08922848985953764 accuracy 3.8819875776397517\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "Train loss 0.11414547190989976 accuracy 3.66046511627907\n",
      "Val   loss 0.08883606371554462 accuracy 3.8819875776397517\n",
      "\n",
      "Epoch 10/20\n",
      "----------\n",
      "Train loss 0.11281033499557296 accuracy 3.66046511627907\n",
      "Val   loss 0.08847445114092393 accuracy 3.8819875776397517\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "Train loss 0.1100725382566452 accuracy 3.66046511627907\n",
      "Val   loss 0.08802533928643573 accuracy 3.8819875776397517\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "Train loss 0.1117989950939829 accuracy 3.66046511627907\n",
      "Val   loss 0.08769032494588332 accuracy 3.8819875776397517\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "Train loss 0.11100845204459296 accuracy 3.66046511627907\n",
      "Val   loss 0.08749642663381317 accuracy 3.8819875776397517\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "Train loss 0.10936445650863058 accuracy 3.66046511627907\n",
      "Val   loss 0.08720900186083534 accuracy 3.8819875776397517\n",
      "\n",
      "Epoch 15/20\n",
      "----------\n",
      "Train loss 0.10895092578397857 accuracy 3.66046511627907\n",
      "Val   loss 0.08707698570056395 accuracy 3.8819875776397517\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "Train loss 0.110945354503246 accuracy 3.66046511627907\n",
      "Val   loss 0.08693285117095167 accuracy 3.8819875776397517\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n",
      "Train loss 0.10753403967361391 accuracy 3.66046511627907\n",
      "Val   loss 0.08689120479605415 accuracy 3.8819875776397517\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "Train loss 0.10955862310013653 accuracy 3.66046511627907\n",
      "Val   loss 0.08679098737510768 accuracy 3.8819875776397517\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "Train loss 0.10923178199632669 accuracy 3.66046511627907\n",
      "Val   loss 0.08676093613559549 accuracy 3.8819875776397517\n",
      "\n",
      "Epoch 20/20\n",
      "----------\n",
      "Train loss 0.11015500873327255 accuracy 3.66046511627907\n",
      "Val   loss 0.08675625615499237 accuracy 3.8819875776397517\n",
      "\n",
      "Wall time: 15h 42min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_data_loader,    \n",
    "        loss_fn, \n",
    "        optimizer, \n",
    "        device, \n",
    "        scheduler, \n",
    "        len(df_train)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_data_loader,\n",
    "        loss_fn, \n",
    "        device, \n",
    "        len(df_val)\n",
    "    )\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        torch.save(model.state_dict(), 'best_model_state_opinion.bin')\n",
    "        best_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a23fc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4439]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4312]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.5063]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4404]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4277]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3604]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4201]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4092]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3378]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3527]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2990]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.2773]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4113]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.4314]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3579]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3567]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4971]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3551]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.4130]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.5197]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2050]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3996]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2244]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3382]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3866]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4345]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3838]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4795]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3773]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2917]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4378]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.1871]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.8000])\n",
      "tensor([[0.4195]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4335]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4698]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.5047]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3565]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.1667]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.1525]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.9000])\n",
      "tensor([[0.2805]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4722]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4118]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3634]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3031]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2091]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.3141]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3693]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3452]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3189]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3863]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4179]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.2838]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3679]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3395]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4843]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3485]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4683]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4706]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3497]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.1350]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2764]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.2904]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.7000])\n",
      "tensor([[0.3272]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4597]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4402]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.5125]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3914]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3794]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4529]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3699]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3732]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3329]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3843]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3961]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4715]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.1980]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2654]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4576]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4172]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4096]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3317]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4389]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3896]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.1893]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4079]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.1556]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3503]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.2417]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3024]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.2411]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4453]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3156]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3825]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3792]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3130]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.2153]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.6000])\n",
      "tensor([[0.5197]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2822]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.1869]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4222]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.1457]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4670]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4978]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.5328]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.2750]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3541]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.2819]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4251]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4085]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3766]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4143]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.3916]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3976]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3178]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3875]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.5093]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4471]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3048]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4259]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4049]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2783]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3288]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.3231]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.5116]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4504]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4182]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.5134]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3343]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.4000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4361]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.1012]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.5000])\n",
      "tensor([[0.3860]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3558]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4228]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3421]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.5191]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3724]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.2929]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3319]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4345]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3087]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3379]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4043]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2602]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.3000])\n",
      "tensor([[0.2866]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4570]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4731]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3950]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3902]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4725]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3905]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3274]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3895]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4998]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.5116]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4872]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.5246]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3591]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3816]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.0467]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.4000])\n",
      "tensor([[0.3896]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.2733]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3298]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3680]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4356]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4886]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3897]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4985]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4148]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.2987]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.2517]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3280]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4382]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4711]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.2661]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4275]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4894]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.5478]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3988]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4632]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.3310]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4138]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.3221]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3930]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4794]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3843]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3735]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.6000])\n",
      "tensor([[0.2003]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3025]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4099]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4778]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2454]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2566]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3698]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4492]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.3846]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.2687]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4404]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3111]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4760]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4304]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4123]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4223]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.4245]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4100]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3568]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4322]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3529]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.3000])\n",
      "tensor([[0.3351]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.4000])\n",
      "tensor([[0.3551]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4011]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4464]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3190]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4311]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.2213]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4038]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.3526]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4702]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.1987]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.3000])\n",
      "tensor([[0.3463]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4952]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3688]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4591]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.3696]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4497]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4275]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3785]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3793]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.2841]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3061]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3485]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3800]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4405]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4387]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.9000])\n",
      "tensor([[0.3628]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3901]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4456]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3589]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4234]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3015]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4029]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.2795]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3395]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3860]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4275]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2375]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.8000])\n",
      "tensor([[0.2830]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3466]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.5239]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2345]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3923]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4565]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.1098]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4776]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3714]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4593]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3722]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.9000])\n",
      "tensor([[0.1874]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.9000])\n",
      "tensor([[0.3621]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4068]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.2404]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.3918]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2986]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2974]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3237]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.5000])\n",
      "tensor([[0.2885]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2341]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.9000])\n",
      "tensor([[0.4148]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3514]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3124]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.4000])\n",
      "tensor([[0.4243]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4122]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.0786]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3382]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3697]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4066]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3846]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4148]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4125]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4536]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4611]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3550]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2215]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4490]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4566]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.1969]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.2000])\n",
      "tensor([[0.3953]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.2452]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3958]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4993]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.3665]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4184]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.1705]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3885]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2064]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3492]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2447]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4237]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3174]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4910]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4436]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3588]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4652]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2124]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3934]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4483]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4737]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4981]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4912]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.5463]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3765]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.7000])\n",
      "tensor([[0.4044]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.3724]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3481]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3723]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4029]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4315]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3635]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2861]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4706]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4345]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.2865]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2620]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3889]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.3801]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4636]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.5297]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.5225]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.5114]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4977]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4376]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3455]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3746]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3802]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4202]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3413]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4379]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4688]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4476]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3951]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4339]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3301]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3564]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4277]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4164]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4406]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4497]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4535]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3697]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3277]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3278]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4446]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3600]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4895]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3494]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3728]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4737]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4692]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4378]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4591]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4679]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3037]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3671]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4793]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3639]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2442]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4123]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2934]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3980]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3221]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3474]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2995]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4358]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3442]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.5123]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.5134]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3619]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.2683]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3306]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3936]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3442]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3055]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4360]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3907]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3404]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4116]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4970]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4215]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3459]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3424]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4586]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4308]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4252]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.0838]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4321]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3840]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4094]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3594]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.9000])\n",
      "tensor([[0.3603]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.1937]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.6000])\n",
      "tensor([[0.3684]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4728]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4464]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3936]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3774]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.5002]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3891]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4678]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4287]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.1836]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.2842]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.5103]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3127]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3715]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3001]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.2000])\n",
      "tensor([[0.3877]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3923]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3250]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3176]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4147]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4208]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4702]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.9000])\n",
      "tensor([[0.3177]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.6000])\n",
      "tensor([[0.3367]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.5197]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2399]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4118]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4637]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.3784]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4144]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3876]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.2932]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4704]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.5304]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3815]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.1831]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4042]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.1347]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3609]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3888]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4359]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.2652]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4291]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.5202]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4919]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.3621]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4205]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4784]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3989]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4654]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4692]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3996]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3816]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.5197]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4225]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3525]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2914]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.3000])\n",
      "tensor([[0.3854]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.3631]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.9000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4660]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4029]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.3294]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.1436]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.3000])\n",
      "tensor([[0.4549]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2245]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3540]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.2940]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.3198]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.5393]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4517]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2252]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.1912]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3380]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4126]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.2262]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4790]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.9000])\n",
      "tensor([[0.2794]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4044]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3735]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4104]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3371]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3143]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4656]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2931]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4677]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4268]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3771]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.8000])\n",
      "tensor([[0.3049]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4215]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2557]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.0721]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4115]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.2720]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3582]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3406]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3853]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3199]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4344]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4533]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.4249]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.2821]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4192]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.1979]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3748]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.5400]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.3963]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3228]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.3654]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4442]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.2770]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3589]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4053]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4432]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2983]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.4000])\n",
      "tensor([[0.4342]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.2246]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.5037]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.2025]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.5173]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3400]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.3748]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3773]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.1795]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.4388]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4180]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3306]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4833]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3265]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3989]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3858]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3224]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2954]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.1150]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2395]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3370]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3547]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3282]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.1740]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3670]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4013]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3769]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.1345]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.5783]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.1083]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3962]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4330]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3513]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.3286]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3896]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3537]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4287]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4424]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.9000])\n",
      "tensor([[0.4420]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.0396]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3637]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3463]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3736]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3572]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4032]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4188]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4211]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4398]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4510]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4201]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4514]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4360]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4016]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3667]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.0709]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3797]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4568]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4329]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4797]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3231]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4752]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3994]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.9000])\n",
      "tensor([[0.4117]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4479]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.4636]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.3000])\n",
      "tensor([[0.2967]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3646]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3614]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3765]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3810]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4681]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.1426]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.7000])\n",
      "tensor([[0.2409]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.9000])\n",
      "tensor([[0.4242]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3376]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.4000])\n",
      "tensor([[0.4074]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4733]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4557]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3234]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4295]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.3951]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.2692]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4263]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.4577]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3720]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4069]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3570]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4083]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3462]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.5305]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2843]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4883]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3202]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3242]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3193]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4075]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3557]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3960]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4318]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4973]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4333]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4291]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4009]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4394]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.2685]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.2312]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4763]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2620]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4183]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.2000])\n",
      "tensor([[0.4620]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4569]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3489]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.8000])\n",
      "tensor([[0.4157]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3947]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4203]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4624]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3314]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3234]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.3349]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4363]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3254]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4364]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.5197]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4015]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2873]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2072]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3387]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4162]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.2745]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3702]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.2116]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4505]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4078]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3526]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3402]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.0905]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.2000])\n",
      "tensor([[0.3556]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4353]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3355]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.3004]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.7000])\n",
      "tensor([[0.3345]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3914]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3944]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3452]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4343]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3666]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2790]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3051]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4372]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.5116]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.1998]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3630]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3510]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3563]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3304]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.2953]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.6000])\n",
      "tensor([[0.3997]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3311]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3270]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.2907]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4467]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3200]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.4434]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4566]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.2410]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3786]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4180]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.2031]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3816]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4676]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2069]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.5051]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4004]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4975]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.4350]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.5647]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4394]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.2854]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4737]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.1877]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4409]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.0758]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4343]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3536]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.3000])\n",
      "tensor([[0.4577]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.1266]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.3000])\n",
      "tensor([[0.4053]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.3984]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3888]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4087]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4303]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3965]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4513]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.5160]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4830]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.1239]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4520]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4174]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.9000])\n",
      "tensor([[0.3503]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3652]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3333]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3183]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.1682]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.5126]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.5246]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.1443]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3816]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3507]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4175]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.2940]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3500]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4733]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.2595]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.3104]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.4382]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.3399]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4491]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4469]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3154]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.5669]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4255]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.1500]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2563]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.9000])\n",
      "tensor([[0.4351]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.5197]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3019]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4178]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4311]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.1545]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.8000])\n",
      "tensor([[0.2022]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4532]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2954]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.5118]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4863]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4756]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.5000])\n",
      "tensor([[0.4381]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3122]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4093]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.1940]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3361]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3261]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.5279]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3877]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4612]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.2987]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3615]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3789]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.5225]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.2649]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3988]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4522]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4401]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4373]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3042]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.2770]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.6000])\n",
      "tensor([[0.3768]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4387]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4485]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4218]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.1874]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4587]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.5463]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4333]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.5055]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3360]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.3000])\n",
      "tensor([[0.4196]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3117]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3712]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.1201]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4324]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3644]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4187]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.2412]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4933]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4752]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4468]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4457]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4027]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3125]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.5553]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4334]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3097]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3938]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4335]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4469]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3334]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3466]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4287]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4863]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3054]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3428]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.5221]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3125]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.5178]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.2002]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4115]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3047]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3822]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4424]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3497]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4656]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.1807]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.9000])\n",
      "tensor([[0.4192]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4294]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4125]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.2036]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.5483]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3995]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4563]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.2361]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.5272]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2099]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2116]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3767]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3880]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4387]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3046]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.3000])\n",
      "tensor([[0.5054]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2845]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3794]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3731]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3045]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.3000])\n",
      "tensor([[0.3855]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.4000])\n",
      "tensor([[0.3810]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3893]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3256]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3112]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4829]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3984]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3879]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3151]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2086]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3831]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3234]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4612]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.3095]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3714]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4403]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4647]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.1877]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4052]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.1953]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.5000])\n",
      "tensor([[0.4104]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3733]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2694]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3891]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.3886]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3469]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3992]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.2055]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.2465]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.2741]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4145]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3531]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.4000])\n",
      "tensor([[0.3681]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4555]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.2090]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.3775]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4176]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4591]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.0201]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3558]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.2000])\n",
      "tensor([[0.3790]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.2058]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4882]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3087]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4811]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.5043]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3318]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3889]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3712]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4656]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.5197]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2869]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4513]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4511]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.9000])\n",
      "tensor([[0.3876]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2598]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.6000])\n",
      "tensor([[0.3942]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4723]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3119]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2541]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4931]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3970]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2373]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.2914]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3478]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.2870]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4067]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3939]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3412]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.3377]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4367]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.1914]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.9000])\n",
      "tensor([[0.4717]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4928]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.9000])\n",
      "tensor([[0.4593]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3415]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.5195]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2302]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3779]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2217]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3247]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.3657]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4822]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4945]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.5054]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3951]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3613]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4557]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.1360]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3339]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3759]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3575]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.5478]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4652]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4389]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3084]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3804]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3881]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.7000])\n",
      "tensor([[0.4098]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.1100]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4879]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3365]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4433]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2640]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4169]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3041]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4148]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.5483]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3329]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.3726]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4847]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3508]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4641]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4768]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3644]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4905]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.2726]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4529]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3791]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3974]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4309]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.2994]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.1913]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4447]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3377]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3533]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4784]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.4858]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3946]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3890]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.5232]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3621]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3053]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.1476]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.2543]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4498]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.2622]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2224]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4644]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.2506]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3120]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.3000])\n",
      "tensor([[0.2840]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.6000])\n",
      "tensor([[0.4488]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3679]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.2314]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3714]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4744]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3668]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4577]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3401]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4033]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4564]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3481]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.2899]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4030]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4594]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3190]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3322]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3892]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3688]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3164]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.2429]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3088]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3762]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4980]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.9000])\n",
      "tensor([[0.3501]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4669]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4600]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4948]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3432]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3151]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.1733]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.9000])\n",
      "tensor([[0.3789]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4486]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2560]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4509]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3073]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3245]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4540]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3705]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4155]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3386]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.3101]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.5003]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3167]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3858]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.4000])\n",
      "tensor([[0.3638]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3387]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3424]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4468]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3650]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4535]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.1814]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4716]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4119]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.4456]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4138]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.2580]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.2000])\n",
      "tensor([[0.3097]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.3831]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3692]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3475]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2984]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3100]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.3407]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4484]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3385]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3245]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3254]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.2904]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3941]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4786]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.5107]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3148]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.3891]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.1700]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4404]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.0451]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.6000])\n",
      "tensor([[0.3145]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.2085]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.2000])\n",
      "tensor([[0.4835]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3465]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.5478]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4990]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4922]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3535]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3538]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3401]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.4242]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4505]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2223]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4147]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4240]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3861]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.2096]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.8000])\n",
      "tensor([[0.3932]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.3608]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3946]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3802]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4536]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4713]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.2471]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.4000])\n",
      "tensor([[0.4294]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4268]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4562]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3913]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.5094]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3308]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.3042]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4207]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4013]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.9000])\n",
      "tensor([[0.3191]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.3548]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.4727]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3875]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3412]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4570]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3099]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3240]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3391]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3954]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3606]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2682]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.2822]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4144]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4546]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3779]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4251]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.1712]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.2480]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4864]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.2886]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4512]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.3255]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2859]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.4075]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3427]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4220]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.5000])\n",
      "tensor([[0.3696]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4629]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.2620]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.4000])\n",
      "tensor([[0.3334]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.4218]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.2950]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3668]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4904]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3664]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.4363]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.4709]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.2645]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.3673]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3687]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.2000])\n",
      "tensor([[0.4320]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.1372]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.5016]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3216]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.5478]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.4000])\n",
      "tensor([[0.3855]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.2873]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.3000])\n",
      "tensor([[0.2041]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3539]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3110]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.5000])\n",
      "tensor([[0.1797]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3990]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.8000])\n",
      "tensor([[0.3505]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2913]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.4761]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3654]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5000])\n",
      "tensor([[0.3012]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.1830]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4793]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3535]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4415]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.1953]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.5127]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.3000])\n",
      "tensor([[0.4042]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.6000])\n",
      "tensor([[0.4086]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3439]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4391]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3649]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.7000])\n",
      "tensor([[0.3602]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.0965]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2204]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "sumaa=0\n",
    "for i in train_data_loader:\n",
    "    for j in range(len(i['input_ids'])-1):\n",
    "        print(model(input_ids=i['input_ids'][j:j+1],attention_mask=i['attention_mask'][j:j+1]))\n",
    "        print(i['targets'][j])\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
